{"meta":{"title":"LsWisdom的博客","subtitle":"谋事在人成事在天","description":"谋事在人成事在天","author":"ls","url":"https://lswisdom.github.io","root":"/"},"pages":[{"title":"tags","date":"2021-04-05T09:00:54.000Z","updated":"2021-04-05T10:37:34.640Z","comments":true,"path":"tags/index.html","permalink":"https://lswisdom.github.io/tags/index.html","excerpt":"","text":""},{"title":"博客分类","date":"2021-04-05T10:40:01.000Z","updated":"2021-04-05T12:11:35.779Z","comments":true,"path":"categories/index.html","permalink":"https://lswisdom.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"证书生成方式","slug":"证书生成方式","date":"2021-07-25T09:43:36.000Z","updated":"2021-08-15T12:53:11.092Z","comments":true,"path":"posts/221454774/","link":"","permalink":"https://lswisdom.github.io/posts/221454774/","excerpt":"","text":"1.为服务器生成证书1keytool -genkey -v -alias tomcat -keyalg RSA -keystore E:\\download\\tomcat.keystore -validity 36500 2.为客户端生成证书1keytool -genkey -v -alias mykey -keyalg RSA -storetype PKCS12 -keystore E:\\download\\mykey.p12 会生成一个客户端的证书 3.让服务器信任客户端证书1keytool -export -alias mykey -keystore E:\\downlaod\\mykey.p12 -storetype PKCS12 -storepass 123456 -rfc -file E:\\downlaod\\mykey.cer 4.将该文件导入服务器的证书库，添加一个信任证书命令1keytool -import -v -file E:\\download\\mykey.cer -keystore E:\\download\\tomcat.keystore 5.查看证书命令：1keytool -list -keystore E:\\download\\tomcat.keystore 6.让客户端信任服务器证书1keytool -keystore E:\\download\\tomcat.keystore -export -alias tomcat -file E:\\download\\tomcat.cer(tomcat为你设置服务器端的证书名) 7.配置tomcat的服务器123456789101112131415&lt;Connector port=&quot;8443&quot; protocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot; SSLEnabled=&quot;true&quot; maxThreads=&quot;150&quot; scheme=&quot;https&quot; secure=&quot;true&quot; clientAuth=&quot;false&quot; sslProtocol=&quot;TLS&quot; keystoreFile=&quot;E:\\download\\tomcat.keystore&quot; keystorePass=&quot;123456&quot; /&gt; 8.把cas里面的证书位置替换一下cas/WEB-INF/classes/application.properties 1server.ssl.key-store&#x3D;E:\\download\\tomcat.keystore 在e:download文件夹中执行cmd 会生成一个证书 1keytool -import -alias tomcat -keystore cacerts -file tomcat.cer 复制该文件，并替换java目录下面的证书文件 1C:\\Program Files\\Java\\jdk1.8.0_251\\jre\\lib\\security","categories":[],"tags":[]},{"title":"SpringBoot项目中配置druid的监控","slug":"springboot/SpringBoot项目中配置druid的监控","date":"2021-07-25T09:33:51.000Z","updated":"2021-07-25T12:42:55.511Z","comments":true,"path":"posts/3895306588/","link":"","permalink":"https://lswisdom.github.io/posts/3895306588/","excerpt":"","text":"SpringBoot项目中配置druid的监控Druid是Java语言中最好的数据库连接池，并且能够提供强大的监控和扩展功能。 Spring Boot默认的数据源是：org.apache.tomcat.jdbc.pool.DataSource 步骤，直接copy到项目中即可，更改部分自己的数据 1.导入pom依赖文件12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.28&lt;/version&gt; &lt;/dependency&gt; 2.配置数据源的相关信息1234567891011121314151617181920212223242526272829#配置数据源的操作spring: datasource: type: com.alibaba.druid.pool.DruidDataSource driverClassName: com.mysql.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/bootdo?useUnicode=true&amp;characterEncoding=utf8 username: root password: root initialSize: 1 minIdle: 3 maxActive: 20 # 配置获取连接等待超时的时间 maxWait: 60000 # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 timeBetweenEvictionRunsMillis: 60000 # 配置一个连接在池中最小生存的时间，单位是毫秒 minEvictableIdleTimeMillis: 30000 validationQuery: select &#x27;x&#x27; testWhileIdle: true testOnBorrow: false testOnReturn: false # 打开PSCache，并且指定每个连接上PSCache的大小 poolPreparedStatements: true maxPoolPreparedStatementPerConnectionSize: 20 # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，&#x27;wall&#x27;用于防火墙 filters: stat,wall,slf4j # 通过connectProperties属性来打开mergeSql功能；慢SQL记录 connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000 # 合并多个DruidDataSource的监控数据 3.创建一个拦截器器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119/** * Created by lishuai on 2019/1/8 14:02 Druid监控信息 */@SuppressWarnings(&quot;AlibabaRemoveCommentedCode&quot;)@Configurationpublic class DruidDBConfig &#123; private Logger logger = LoggerFactory.getLogger(DruidDBConfig.class); @Value(&quot;$&#123;spring.datasource.url&#125;&quot;) private String dbUrl; @Value(&quot;$&#123;spring.datasource.username&#125;&quot;) private String username; @Value(&quot;$&#123;spring.datasource.password&#125;&quot;) private String password; @Value(&quot;$&#123;spring.datasource.driverClassName&#125;&quot;) private String driverClassName; @Value(&quot;$&#123;spring.datasource.initialSize&#125;&quot;) private int initialSize; @Value(&quot;$&#123;spring.datasource.minIdle&#125;&quot;) private int minIdle; @Value(&quot;$&#123;spring.datasource.maxActive&#125;&quot;) private int maxActive; @Value(&quot;$&#123;spring.datasource.maxWait&#125;&quot;) private int maxWait; @Value(&quot;$&#123;spring.datasource.timeBetweenEvictionRunsMillis&#125;&quot;) private int timeBetweenEvictionRunsMillis; @Value(&quot;$&#123;spring.datasource.minEvictableIdleTimeMillis&#125;&quot;) private int minEvictableIdleTimeMillis; @Value(&quot;$&#123;spring.datasource.validationQuery&#125;&quot;) private String validationQuery; @Value(&quot;$&#123;spring.datasource.testWhileIdle&#125;&quot;) private boolean testWhileIdle; @Value(&quot;$&#123;spring.datasource.testOnBorrow&#125;&quot;) private boolean testOnBorrow; @Value(&quot;$&#123;spring.datasource.testOnReturn&#125;&quot;) private boolean testOnReturn; @Value(&quot;$&#123;spring.datasource.poolPreparedStatements&#125;&quot;) private boolean poolPreparedStatements; @Value(&quot;$&#123;spring.datasource.maxPoolPreparedStatementPerConnectionSize&#125;&quot;) private int maxPoolPreparedStatementPerConnectionSize; @Value(&quot;$&#123;spring.datasource.filters&#125;&quot;) private String filters; @Value(&quot;&#123;spring.datasource.connectionProperties&#125;&quot;) private String connectionProperties; @Bean(initMethod = &quot;init&quot;, destroyMethod = &quot;close&quot;) //声明其为Bean实例 @Primary //在同样的DataSource中，首先使用被标注的DataSource public DataSource dataSource() &#123; DruidDataSource datasource = new DruidDataSource(); datasource.setUrl(this.dbUrl); datasource.setUsername(username); datasource.setPassword(password); datasource.setDriverClassName(driverClassName); //configuration datasource.setInitialSize(initialSize); datasource.setMinIdle(minIdle); datasource.setMaxActive(maxActive); datasource.setMaxWait(maxWait); datasource.setTimeBetweenEvictionRunsMillis(timeBetweenEvictionRunsMillis); datasource.setMinEvictableIdleTimeMillis(minEvictableIdleTimeMillis); datasource.setValidationQuery(validationQuery); datasource.setTestWhileIdle(testWhileIdle); datasource.setTestOnBorrow(testOnBorrow); datasource.setTestOnReturn(testOnReturn); datasource.setPoolPreparedStatements(poolPreparedStatements); datasource.setMaxPoolPreparedStatementPerConnectionSize(maxPoolPreparedStatementPerConnectionSize); try &#123; datasource.setFilters(filters); &#125; catch (SQLException e) &#123; logger.error(&quot;druid configuration initialization filter&quot;, e); &#125; datasource.setConnectionProperties(connectionProperties); return datasource; &#125; @Bean public ServletRegistrationBean druidServlet() &#123; ServletRegistrationBean reg = new ServletRegistrationBean(); reg.setServlet(new StatViewServlet()); reg.addUrlMappings(&quot;/druid/*&quot;); reg.addInitParameter(&quot;allow&quot;, &quot;&quot;); //白名单 return reg; &#125; @Bean public FilterRegistrationBean filterRegistrationBean() &#123; FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(); filterRegistrationBean.setFilter(new WebStatFilter()); filterRegistrationBean.addUrlPatterns(&quot;/*&quot;); filterRegistrationBean.addInitParameter(&quot;exclusions&quot;, &quot;*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*&quot;); filterRegistrationBean.addInitParameter(&quot;profileEnable&quot;, &quot;true&quot;); filterRegistrationBean.addInitParameter(&quot;principalCookieName&quot;,&quot;USER_COOKIE&quot;); filterRegistrationBean.addInitParameter(&quot;principalSessionName&quot;,&quot;USER_SESSION&quot;); filterRegistrationBean.addInitParameter(&quot;DruidWebStatFilter&quot;,&quot;/*&quot;); return filterRegistrationBean; &#125;&#125; http://localhost:8080/druid/index.html 就可以访问主界面了","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://lswisdom.github.io/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot -","slug":"SpringBoot","permalink":"https://lswisdom.github.io/tags/SpringBoot/"}]},{"title":"Centos7安装Redis","slug":"linux/Centos7安装Redis","date":"2021-07-25T09:17:42.000Z","updated":"2021-07-25T09:29:34.546Z","comments":true,"path":"posts/2813726945/","link":"","permalink":"https://lswisdom.github.io/posts/2813726945/","excerpt":"","text":"一、CentOS7单节点安装Redis注意：安装redis需要先将官网下载的源码进行编译，编译依赖gcc环境，如果没有gcc环境，需要安装,否则编译时会报错 1yum install make cmake gcc gcc-c++ 1. 下载redis安装包1wget http:&#x2F;&#x2F;download.redis.io&#x2F;releases&#x2F;redis-5.0.0.tar.gz 2.解压1tar -xzvf redis-5.0.0.tar.gz 3.进入redis目录下编译1make 4.指定安装目录安装，PREFIX参数指定redis的安装目录，命令如下 1make install PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;software&#x2F;redis 5.启动redis进入安装后的路径，就是cd /usr/local/software/redis 在bin目录下执行 cd bin 1 .&#x2F;redis-server 这是redis的前台启动，缺点是ssh命令窗口关了之后服务就会停止 6.设置后台启动 把redis源码包解压目录下的redis.conf复制到安装目录的bin下 1cp &#x2F;usr&#x2F;local&#x2F;software&#x2F;redis-5.0.0&#x2F;redis.conf &#x2F;usr&#x2F;local&#x2F;software&#x2F;redis&#x2F;bin 修改配置文件（bin下面的redis.conf）：redis默认只能本机访问，要把下面两句改一下才能远程访问 #bind 127.0.0.1 注释掉 关闭保护模式 protected-mode no 以守护进程后台模式运行 daemonize yes 在bin目录下执行./redis-server redis.conf 检查是否启动完成 1ps ef | grep redis 7.开放端口号有时候可能会出现连接不上的情况，要注意开放端口号 打开6379端口防火墙方法： 执行命令打开6379端口防火墙，看到success字样就表明添加成功 1firewall-cmd --zone&#x3D;public --add-port&#x3D;6379&#x2F;tcp --permanent 然后重新启动防火墙，看到success字样就表明重启成功 1firewall-cmd --reload 验证是否生效 1firewall-cmd --zone&#x3D;public --query-port&#x3D;6379&#x2F;tcp 开放完端口号后，连接一下就可以了 8.redis.conf配置详解redis.conf 里面有一些配置，可以根据需要修改，比如说添加认证密码。修改端口号等 redis.conf配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331. Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程daemonize no2. 当Redis以守护进程方式运行时，Redis默认会把pid写入&#x2F;var&#x2F;run&#x2F;redis.pid文件，可以通过pidfile指定pidfile &#x2F;var&#x2F;run&#x2F;redis.pid3. 指定Redis监听端口，默认端口为6379，为什么选用6379作为默认端口，因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字port 63794. 绑定的主机地址bind 127.0.0.15.当 客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能timeout 3006. 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verboseloglevel verbose7. 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给&#x2F;dev&#x2F;nulllogfile stdout8. 设置数据库的数量，默认数据库为0，可以使用SELECT &lt;dbid&gt;命令在连接上指定数据库iddatabases 169. 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合save &lt;seconds&gt; &lt;changes&gt;Redis默认配置文件中提供了三个条件：save 900 1save 300 10save 60 10000分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。10. 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大rdbcompression yes11. 指定本地数据库文件名，默认值为dump.rdbdbfilename dump.rdb12. 指定本地数据库存放目录dir .&#x2F;13. 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步slaveof &lt;masterip&gt; &lt;masterport&gt;14. 当master服务设置了密码保护时，slav服务连接master的密码masterauth &lt;master-password&gt;15. 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH &lt;password&gt;命令提供密码，默认关闭requirepass foobared16. 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息maxclients 12817. 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区maxmemory &lt;bytes&gt;18. 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为noappendonly no19. 指定更新日志文件名，默认为appendonly.aofappendfilename appendonly.aof20. 指定更新日志条件，共有3个可选值： no：表示等操作系统进行数据缓存同步到磁盘（快） always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全） everysec：表示每秒同步一次（折中，默认值）appendfsync everysec21. 指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中（在后面的文章我会仔细分析Redis的VM机制）vm-enabled no22. 虚拟内存文件路径，默认值为&#x2F;tmp&#x2F;redis.swap，不可多个Redis实例共享vm-swap-file &#x2F;tmp&#x2F;redis.swap23. 将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0vm-max-memory 024. Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值vm-page-size 3225. 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，，在磁盘上每8个pages将消耗1byte的内存。vm-pages 13421772826. 设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4vm-max-threads 427. 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启glueoutputbuf yes28. 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法hash-max-zipmap-entries 64hash-max-zipmap-value 51229. 指定是否激活重置哈希，默认为开启（后面在介绍Redis的哈希算法时具体介绍）activerehashing yes30. 指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件include &#x2F;path&#x2F;to&#x2F;local.confredis.conf配置","categories":[{"name":"Redis","slug":"Redis","permalink":"https://lswisdom.github.io/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://lswisdom.github.io/tags/Redis/"}]},{"title":"Centos7开启防火墙命令","slug":"linux/Centos7开启防火墙命令","date":"2021-07-25T09:13:26.000Z","updated":"2021-07-25T09:16:56.971Z","comments":true,"path":"posts/3592562801/","link":"","permalink":"https://lswisdom.github.io/posts/3592562801/","excerpt":"","text":"打开6379端口防火墙方法： 执行命令打开6379端口防火墙，看到success字样就表明添加成功 1firewall-cmd --zone&#x3D;public --add-port&#x3D;6379&#x2F;tcp --permanent 然后重新启动防火墙，看到success字样就表明重启成功 1firewall-cmd --reload 最后可以输入命令验证6379端口打开是否生效，看到yes及表示生效 1firewall-cmd --zone&#x3D;public --query-port&#x3D;6379&#x2F;tcp 重试一下，就可以连接了","categories":[{"name":"linux","slug":"linux","permalink":"https://lswisdom.github.io/categories/linux/"}],"tags":[]},{"title":"centos7安装JDK","slug":"linux/centos7安装JDK","date":"2021-07-25T08:54:55.000Z","updated":"2021-07-25T09:01:24.262Z","comments":true,"path":"posts/3393234349/","link":"","permalink":"https://lswisdom.github.io/posts/3393234349/","excerpt":"","text":"基本环境配置1.CentOS7安装JDK1.检查系统中是否存在JDKCentOS一般会自带两个jdk，使用命令查看 12345678910rpm -qa | grep javarpm -e --nodeps 要卸载的包 (包通过上面的指令可以获取到)]如：rpm -e --nodeps java-1.7.0-openjdk-1.7.0.99-2.6.5.1.el6.x86_64rpm -e --nodeps java-1.6.0-openjdk-1.6.0.38-1.13.10.4.el6.x86_64rpm:用于管理套件-e:表示删除指定的套件-q:使用询问模式，当遇到任何问题时，rpm指令会先询问用户。-a:查询所有套件。|:把前一个命令原本要bai输出到屏幕的数据du当作是后一个命令的标准输入 2.上传JDK包上传JDK包到/usr/local/software目录下面 执行解压JDK安装文件 1tar -zxvf jdk-8u151-linux-x64.tar.gz 3.配置环境变量vim /etc/profile 在文件最末尾加上下面几句话 12345export JAVA_HOME=/usr/local/software/jdk1.8.0_151export JRE_HOME=/usr/local/software/jdk1.8.0_151/jreexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libexport PATH=$PATH:$JAVA_HOME/bin 保存退出 让配置生效： source /etc/profile 检查环境： 运行java –version能看到版本信息","categories":[{"name":"linux","slug":"linux","permalink":"https://lswisdom.github.io/categories/linux/"}],"tags":[{"name":"Linux环境安装","slug":"Linux环境安装","permalink":"https://lswisdom.github.io/tags/Linux%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"}]},{"title":"ElasticSearch的API使用","slug":"elasticsearch/ElasticSearch的API使用","date":"2021-07-25T03:22:05.000Z","updated":"2021-07-25T09:09:38.067Z","comments":true,"path":"posts/2227500636/","link":"","permalink":"https://lswisdom.github.io/posts/2227500636/","excerpt":"","text":"ES API的使用说明：Es是基于JAVA开发的，可以直接导入依赖依赖包，调用Es提供的API进行访问 一、环境准备1.导入pom文件123456789101112&lt;!-- https://mvnrepository.com/artifact/org.elasticsearch/elasticsearch --&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;7.12.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.elasticsearch.client/elasticsearch-rest-high-level-client --&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;7.12.0&lt;/version&gt; &lt;/dependency&gt; 二、基本API操作1.索引操作1.1 创建索引123456789101112131415161718192021222324252627282930/** * ES高级客户端连接 * * @author Administrator */@Data@Slf4jpublic class EsHighClientCreateIndex &#123; public static void main(String[] args) throws IOException &#123; // 1.创建Es高级客户端 HttpHost httpHost = new HttpHost(&quot;192.168.142.133&quot;, 9200, &quot;http&quot;); RestClientBuilder restClientBuilder = RestClient.builder(httpHost); RestHighLevelClient esClient = new RestHighLevelClient(restClientBuilder); // 2.创建索引 CreateIndexRequest createIndexRequest = new CreateIndexRequest(&quot;create_index_test&quot;); // indices是提供一个IndicesClient 客户端,用来连接索引的API // create 创建索引的API ,两个参数一个是请求,一个给出默认选项即可 CreateIndexResponse createIndexResponse = esClient.indices().create(createIndexRequest, RequestOptions.DEFAULT); // 返回是否响应 true如果应答被确认，否则返回false boolean acknowledged = createIndexResponse.isAcknowledged(); log.info(&quot;索引操作：&quot; + acknowledged); // 关闭客户端 esClient.close(); &#125;&#125; 结果日志如下： es中显示如下： 由此可知，索引已经创建成功了 1.2 查询索引代码演示 12345678910111213141516171819202122232425@Data@Slf4jpublic class EsHighClientQueryIndex &#123; public static void main(String[] args) throws IOException &#123; // 1.创建Es高级客户端 HttpHost httpHost = new HttpHost(&quot;192.168.142.133&quot;, 9200, &quot;http&quot;); RestClientBuilder restClientBuilder = RestClient.builder(httpHost); RestHighLevelClient esClient = new RestHighLevelClient(restClientBuilder); // 2.查询索引 GetIndexRequest getIndexRequest = new GetIndexRequest(&quot;create_index_test&quot;, &quot;order&quot;); // get方法获取一个或多个索引的信息 GetIndexResponse getIndexResponse = esClient.indices().get(getIndexRequest, RequestOptions.DEFAULT); log.info(&quot;Aliases：&#123;&#125;&quot;, getIndexResponse.getAliases()); log.info(&quot;DataStreams: &#123;&#125;&quot;, getIndexResponse.getDataStreams()); log.info(&quot;DefaultSettings: &#123;&#125;&quot;, getIndexResponse.getDefaultSettings()); log.info(&quot;Indices(): &#123;&#125;&quot;, getIndexResponse.getIndices()); log.info(&quot;Mappings: &#123;&#125;&quot;, getIndexResponse.getMappings()); // 关闭客户端 esClient.close(); &#125;&#125; es日志显示如下： 从日志结果可以看到。代码中查询的两个索引数据，都被查询出来了 1.3 删除索引代码演示： 123456789101112131415161718192021@Data@Slf4jpublic class EsHighClientDeleteIndex &#123; public static void main(String[] args) throws IOException &#123; // 1.创建Es高级客户端 HttpHost httpHost = new HttpHost(&quot;192.168.142.133&quot;, 9200, &quot;http&quot;); RestClientBuilder restClientBuilder = RestClient.builder(httpHost); RestHighLevelClient esClient = new RestHighLevelClient(restClientBuilder); // 2.删除索引请求 删除一个或者多个索引 DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(&quot;create_index_test&quot;, &quot;order&quot;); // delete 删除索引的api AcknowledgedResponse response = esClient.indices().delete(deleteIndexRequest, RequestOptions.DEFAULT); log.info(&quot;Acknowledged: &#123;&#125; &quot;,response.isAcknowledged()); // 关闭客户端 esClient.close(); &#125;&#125; 日志结果： 1INFO com.shuai.es.config.EsHighClientDeleteIndex - Acknowledged: true Es数据库索引结果 通过图片上的内容可以看出，”create_index_test”, “order” 两个索引数据已经被删除了","categories":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://lswisdom.github.io/categories/ElasticSearch/"}],"tags":[]},{"title":"ElasticSearch基本语法","slug":"elasticsearch/ElasticSearch基本语法","date":"2021-07-25T02:51:06.000Z","updated":"2021-07-25T09:09:38.180Z","comments":true,"path":"posts/2270907689/","link":"","permalink":"https://lswisdom.github.io/posts/2270907689/","excerpt":"","text":"ElasticSearch基本语法Elastic Stack 包括(ElasticSearch、Kibana、Beats、LogStash) 一、基本概念概念：ElasticSearch是一个开源的高扩展的分布式全文搜索引擎，是整个Elastic Stack的核心。它可以近乎实时的存储、检索数据、本身扩展性很好，可以扩展到多台服务器上。 二、ElasticSearch和Solr的区别 特征 Sorl全文检索 ElasticSearch全文检索 三、数据格式ElasticSearch是面向文档型的数据库，一条数据在这里就是一个文档。 倒排索引： 四、索引操作1.创建索引Put请求具有幂等性，只要发出了同样的请求，结果是一样的 发送Put请求： 1http:&#x2F;&#x2F;192.168.142.132:9200&#x2F;device 创建一个设备索引，返回结果如下： 12345&#123; &quot;acknowledged&quot;: true, &quot;shards_acknowledged&quot;: true, &quot;index&quot;: &quot;device&quot;&#125; 重复调用 1234567891011121314151617&#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;resource_already_exists_exception&quot;, &quot;reason&quot;: &quot;index [device/N7Gu-fYqSw6KEq3ya6tFqQ] already exists&quot;, &quot;index_uuid&quot;: &quot;N7Gu-fYqSw6KEq3ya6tFqQ&quot;, &quot;index&quot;: &quot;device&quot; &#125; ], &quot;type&quot;: &quot;resource_already_exists_exception&quot;, &quot;reason&quot;: &quot;index [device/N7Gu-fYqSw6KEq3ya6tFqQ] already exists&quot;, &quot;index_uuid&quot;: &quot;N7Gu-fYqSw6KEq3ya6tFqQ&quot;, &quot;index&quot;: &quot;device&quot; &#125;, &quot;status&quot;: 400&#125; 如果采用post发送请求 1http:&#x2F;&#x2F;192.168.142.132:9200&#x2F;device 1234&#123; &quot;error&quot;: &quot;Incorrect HTTP method for uri [/device] and method [POST], allowed: [GET, HEAD, DELETE, PUT]&quot;, &quot;status&quot;: 405&#125; 2.获取索引Get是获取请求的方式，只需要更换请求方式就可以获取到需要的数据 只需要更换请求方式，重新调用刚才的接口 1http:&#x2F;&#x2F;192.168.142.132:9200&#x2F;device 返回结果如下： 12345678910111213141516171819202122232425&#123; &quot;device&quot;: &#123; &quot;aliases&quot;: &#123;&#125;, &quot;mappings&quot;: &#123;&#125;, &quot;settings&quot;: &#123; &quot;index&quot;: &#123; &quot;routing&quot;: &#123; &quot;allocation&quot;: &#123; &quot;include&quot;: &#123; &quot;_tier_preference&quot;: &quot;data_content&quot; &#125; &#125; &#125;, &quot;number_of_shards&quot;: &quot;1&quot;, &quot;provided_name&quot;: &quot;device&quot;, &quot;creation_date&quot;: &quot;1626221003499&quot;, &quot;number_of_replicas&quot;: &quot;1&quot;, &quot;uuid&quot;: &quot;N7Gu-fYqSw6KEq3ya6tFqQ&quot;, &quot;version&quot;: &#123; &quot;created&quot;: &quot;7120099&quot; &#125; &#125; &#125; &#125;&#125; 3.获取Es中所有的索引例如： 1http:&#x2F;&#x2F;192.168.142.132:9200&#x2F;_cat&#x2F;indices?v 语法介绍： _cat就是表示查询的意思 get请求方式调用结果如下 health status index uuid pri rep docs.count docs.deleted store.size pri.store.size yellow open users1 p5mf4PlQTOmjyj8kNgDJWQ 1 1 0 0 208b 208b yellow open device N7Gu-fYqSw6KEq3ya6tFqQ 1 1 0 0 208b 208b 4.删除索引使用Delete请求例如： 12DELETE 请求http:&#x2F;&#x2F;192.168.142.132:9200&#x2F;devicehttp:&#x2F;&#x2F;ip地址&#x2F;索引名称 执行语句,返回结果 123&#123; &quot;acknowledged&quot;: true&#125; 在次执行查询索引的结果，返回索引已经删除掉了 五、文档操作1.创建文档文档类似于关系数据库中的一行数据 例如： 123Post 请求 http:&#x2F;&#x2F;192.168.142.132:9200&#x2F;device&#x2F;_docdevice表示索引_doc表示文档 参数放入到请求中,传递数据使用json格式，如下 123456&#123; &quot;deviceId&quot;:&quot;1&quot;, &quot;deviceName&quot;:&quot;电脑&quot;, &quot;devicePrice&quot;:100, &quot;deviceCount&quot;:10000&#125; 返回结果如下： 1234567891011121314&#123; &quot;_index&quot;: &quot;device&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;w2VPp3oBNO_hG4-F_Lmz&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;_seq_no&quot;: 0, &quot;_primary_term&quot;: 1&#125; Id可以是刚才创建的那条数据的唯一标识，随机生成的，同样的请求，多次发生后，产生的结果不一样，所以必须使用post请求 2.自定义创建文档时的id值发送POST请求 12http:&#x2F;&#x2F;192.168.142.133:9200&#x2F;device&#x2F;_doc&#x2F;10086http:&#x2F;&#x2F;ip地址&#x2F;device(索引)&#x2F;_doc(文档)&#x2F;id编号 和上面的同样的json参数，执行结果如下： 1234567891011121314&#123; &quot;_index&quot;: &quot;device&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;10086&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;_seq_no&quot;: 1, &quot;_primary_term&quot;: 2&#125; 可以发现，执行结果里面_id不再是一个随机值，而是我们设置的10086 _doc也可以换成 _create效果一样的 例如： 发送Post请求 1http:&#x2F;&#x2F;192.168.142.133:9200&#x2F;device&#x2F;_create&#x2F;10087 同样的参数，执行结果如下： 1234567891011121314&#123; &quot;_index&quot;: &quot;device&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;10087&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;_seq_no&quot;: 2, &quot;_primary_term&quot;: 2&#125; 可以看到执行结果,已经变成我们自定义的id值10087了 3.查询索引下单条文档数据的方式发送Get请求：http://192.168.142.133:9200/device/_doc/10087 1http:&#x2F;&#x2F;ip地址&#x2F;device(索引)&#x2F;_doc(文档)&#x2F;10087(id值) 执行结果如下： 123456789101112131415&#123; &quot;_index&quot;: &quot;device&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;10087&quot;, &quot;_version&quot;: 1, &quot;_seq_no&quot;: 2, &quot;_primary_term&quot;: 2, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;deviceId&quot;: &quot;1&quot;, &quot;deviceName&quot;: &quot;电脑&quot;, &quot;devicePrice&quot;: 100, &quot;deviceCount&quot;: 10000 &#125;&#125; 可以看到我录入的结果打印出来了 4.查询索引下所有文档数据的方式查询索引下面所有的数据用_search 例如： 12http:&#x2F;&#x2F;192.168.142.133:9200&#x2F;device&#x2F;_doc&#x2F;_searchhttp:&#x2F;&#x2F;ip地址&#x2F;device(索引)&#x2F;_doc(文档)&#x2F;_search(关键字) 查询结果如下； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&#123; &quot;took&quot;: 145, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 1, &quot;successful&quot;: 1, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: &#123; &quot;value&quot;: 3, &quot;relation&quot;: &quot;eq&quot; &#125;, &quot;max_score&quot;: 1.0, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;device&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;w2VPp3oBNO_hG4-F_Lmz&quot;, &quot;_score&quot;: 1.0, &quot;_source&quot;: &#123; &quot;deviceId&quot;: &quot;1&quot;, &quot;deviceName&quot;: &quot;电脑&quot;, &quot;devicePrice&quot;: 100, &quot;deviceCount&quot;: 10000 &#125; &#125;, &#123; &quot;_index&quot;: &quot;device&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;10086&quot;, &quot;_score&quot;: 1.0, &quot;_source&quot;: &#123; &quot;deviceId&quot;: &quot;1&quot;, &quot;deviceName&quot;: &quot;电脑&quot;, &quot;devicePrice&quot;: 100, &quot;deviceCount&quot;: 10000 &#125; &#125;, &#123; &quot;_index&quot;: &quot;device&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;10087&quot;, &quot;_score&quot;: 1.0, &quot;_source&quot;: &#123; &quot;deviceId&quot;: &quot;1&quot;, &quot;deviceName&quot;: &quot;电脑&quot;, &quot;devicePrice&quot;: 100, &quot;deviceCount&quot;: 10000 &#125; &#125; ] &#125;&#125; 可以看到id=10086 和id=10087 和刚才自定义录入的id值已经成功打印出来了 5.更新数据1.全量数据更新更新数据，把需要更新的json直接放入到json后， 使用put请求发送 例如 1PUT 请求 http:&#x2F;&#x2F;192.168.142.133:9200&#x2F;device&#x2F;_doc&#x2F;10086 更新参数信息 12345678910111213&#123; &quot;deviceId&quot;:&quot;1&quot;, &quot;deviceName&quot;:&quot;电脑&quot;, &quot;devicePrice&quot;:100, &quot;deviceCount&quot;:10000&#125;修改后&#123; &quot;deviceId&quot;:&quot;10&quot;, &quot;deviceName&quot;:&quot;电脑10086&quot;, &quot;devicePrice&quot;:99, &quot;deviceCount&quot;:9999&#125; 执行结果如下： 1234567891011121314&#123; &quot;_index&quot;: &quot;device&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;10086&quot;, &quot;_version&quot;: 3, &quot;result&quot;: &quot;updated&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;_seq_no&quot;: 4, &quot;_primary_term&quot;: 2&#125; 每次数据更新_version版本号就会加一 再次使用get请求查询更新后的数据如下：http://192.168.142.133:9200/device/_doc/10086 可以发现数据已经更新了 123456789101112131415&#123; &quot;_index&quot;: &quot;device&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;10086&quot;, &quot;_version&quot;: 3, &quot;_seq_no&quot;: 4, &quot;_primary_term&quot;: 2, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;deviceId&quot;: &quot;10&quot;, &quot;deviceName&quot;: &quot;电脑10086&quot;, &quot;devicePrice&quot;: 99, &quot;deviceCount&quot;: 9999 &#125;&#125; 2.局部数据更新使用_update关键字 1POST请求：http:&#x2F;&#x2F;192.168.142.133:9200&#x2F;device&#x2F;_update&#x2F;10087 JSON参数： 12345&#123; &quot;doc&quot;:&#123; &quot;deviceName&quot;:&quot;电脑测试局部更新数据&quot; &#125;&#125; 返回结果： 1234567891011121314&#123; &quot;_index&quot;: &quot;device&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;10087&quot;, &quot;_version&quot;: 2, &quot;result&quot;: &quot;updated&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;_seq_no&quot;: 3, &quot;_primary_term&quot;: 1&#125; 查询结果如下： 123456789101112131415&#123; &quot;_index&quot;: &quot;device&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;10087&quot;, &quot;_version&quot;: 2, &quot;_seq_no&quot;: 3, &quot;_primary_term&quot;: 1, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;deviceId&quot;: &quot;1&quot;, &quot;deviceName&quot;: &quot;电脑测试局部更新数据&quot;, &quot;devicePrice&quot;: 100, &quot;deviceCount&quot;: 10000 &#125;&#125; 可以看到数据已经更新了 3.删除文档下面的某一条数据更换请求方式为DELETE请求 1DELETE http:&#x2F;&#x2F;192.168.142.133:9200&#x2F;device&#x2F;_doc&#x2F;10087 执行结果如下： 1234567891011121314&#123; &quot;_index&quot;: &quot;device&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;10087&quot;, &quot;_version&quot;: 3, &quot;result&quot;: &quot;deleted&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;_seq_no&quot;: 4, &quot;_primary_term&quot;: 1&#125; result 可以看到结果已经删除了 6.条件查询关键字q 1.GET请求方式例如： 1GET http:&#x2F;&#x2F;192.168.142.133:9200&#x2F;device&#x2F;_search?q&#x3D;deviceName&#x3D;电脑 查询索引库下面所有的deviceName=电脑的数据 结果如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243&#123; &quot;took&quot;: 10, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 1, &quot;successful&quot;: 1, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: &#123; &quot;value&quot;: 2, &quot;relation&quot;: &quot;eq&quot; &#125;, &quot;max_score&quot;: 0.26706278, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;device&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;rWtop3oBkc42Sjumcr4A&quot;, &quot;_score&quot;: 0.26706278, &quot;_source&quot;: &#123; &quot;deviceId&quot;: &quot;1&quot;, &quot;deviceName&quot;: &quot;电脑&quot;, &quot;devicePrice&quot;: 100, &quot;deviceCount&quot;: 10000 &#125; &#125;, &#123; &quot;_index&quot;: &quot;device&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;10086&quot;, &quot;_score&quot;: 0.26706278, &quot;_source&quot;: &#123; &quot;deviceId&quot;: &quot;1&quot;, &quot;deviceName&quot;: &quot;电脑&quot;, &quot;devicePrice&quot;: 100, &quot;deviceCount&quot;: 10000 &#125; &#125; ] &#125;&#125; 2.POST请求方式Match表示匹配 query表示查询 1POST http:&#x2F;&#x2F;192.168.142.133:9200&#x2F;device&#x2F;_search 请求体中参数如下： 1234567&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;deviceName&quot;:&quot;空调&quot; &#125; &#125;&#125; 这是刚加的数据，为了区分 12345678910111213141516171819202122232425262728293031&#123; &quot;took&quot;: 7, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 1, &quot;successful&quot;: 1, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: &#123; &quot;value&quot;: 1, &quot;relation&quot;: &quot;eq&quot; &#125;, &quot;max_score&quot;: 2.4079456, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;device&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;rmt1p3oBkc42SjumgL6w&quot;, &quot;_score&quot;: 2.4079456, &quot;_source&quot;: &#123; &quot;deviceId&quot;: &quot;133&quot;, &quot;deviceName&quot;: &quot;空调&quot;, &quot;devicePrice&quot;: 666, &quot;deviceCount&quot;: 6666 &#125; &#125; ] &#125;&#125; 可以看到只有deviceName”: “空调” 的数据被查询出来了 7.分页查询分页查询From:当前页的起始位置 Size:每页查询的数据条数 计算当前页：（页码-1）*每页数据条数 例如：新增录入10条空调数据，便于测试结果 1POST请求 http:&#x2F;&#x2F;192.168.142.133:9200&#x2F;device&#x2F;_search 参数需要修改下，增加from 和size字段 12345678910&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;deviceName&quot;:&quot;空调&quot; &#125; &#125;, &quot;from&quot;:2, &quot;size&quot;:2&#125; 返回结果如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243&#123; &quot;took&quot;: 3, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 1, &quot;successful&quot;: 1, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: &#123; &quot;value&quot;: 11, &quot;relation&quot;: &quot;eq&quot; &#125;, &quot;max_score&quot;: 0.53140634, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;device&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 0.53140634, &quot;_source&quot;: &#123; &quot;deviceId&quot;: &quot;2&quot;, &quot;deviceName&quot;: &quot;空调&quot;, &quot;devicePrice&quot;: 666, &quot;deviceCount&quot;: 6666 &#125; &#125;, &#123; &quot;_index&quot;: &quot;device&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: 0.53140634, &quot;_source&quot;: &#123; &quot;deviceId&quot;: &quot;3&quot;, &quot;deviceName&quot;: &quot;空调&quot;, &quot;devicePrice&quot;: 666, &quot;deviceCount&quot;: 6666 &#125; &#125; ] &#125;&#125; 可以看到命中了11条数据，数据中只返回了2条数据 Source限制返回字段同样的请求,修改参数,增加_source关键字 1234567891011&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;deviceName&quot;:&quot;空调&quot; &#125; &#125;, &quot;from&quot;:2, &quot;size&quot;:2, &quot;_source&quot;:[&quot;deviceName&quot;]&#125; 返回结果如下： 12345678910111213141516171819202122232425262728293031323334353637&#123; &quot;took&quot;: 5, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 1, &quot;successful&quot;: 1, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: &#123; &quot;value&quot;: 11, &quot;relation&quot;: &quot;eq&quot; &#125;, &quot;max_score&quot;: 0.53140634, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;device&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 0.53140634, &quot;_source&quot;: &#123; &quot;deviceName&quot;: &quot;空调&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;device&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: 0.53140634, &quot;_source&quot;: &#123; &quot;deviceName&quot;: &quot;空调&quot; &#125; &#125; ] &#125;&#125; 可以看到返回结果中，数据对象字段,只返回了我们定义的那一个 8.Sort排序使用Sort字段 例如： 1234567&#123; &quot;sort&quot;:&#123; &quot;money&quot;:&#123; &quot;order&quot;:&quot;desc&quot; &#125; &#125;&#125; 请求实例： 1POST请求 http:&#x2F;&#x2F;192.168.142.133:9200&#x2F;order&#x2F;_search 返回结果： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&#123; &quot;took&quot;: 5, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 1, &quot;successful&quot;: 1, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: &#123; &quot;value&quot;: 3, &quot;relation&quot;: &quot;eq&quot; &#125;, &quot;max_score&quot;: null, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;order&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;z_S-p3oB7hjRu-hq480k&quot;, &quot;_score&quot;: null, &quot;_source&quot;: &#123; &quot;orderId&quot;: &quot;10001&quot;, &quot;money&quot;: 10000, &quot;orderName&quot;: &quot;电脑&quot; &#125;, &quot;sort&quot;: [ 10000 ] &#125;, &#123; &quot;_index&quot;: &quot;order&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;0PTBp3oB7hjRu-hqoc1m&quot;, &quot;_score&quot;: null, &quot;_source&quot;: &#123; &quot;orderId&quot;: &quot;10002&quot;, &quot;money&quot;: 9000, &quot;orderName&quot;: &quot;手机&quot; &#125;, &quot;sort&quot;: [ 9000 ] &#125;, &#123; &quot;_index&quot;: &quot;order&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;0fTBp3oB7hjRu-hq8c0j&quot;, &quot;_score&quot;: null, &quot;_source&quot;: &#123; &quot;orderId&quot;: &quot;10003&quot;, &quot;money&quot;: 8000, &quot;orderName&quot;: &quot;遥控器&quot; &#125;, &quot;sort&quot;: [ 8000 ] &#125; ] &#125;&#125; 可见结果按照降序排序了 9.多条件查询多条件查询字段 bool 多条件同时成立： must 匹配规则：match 请求实例： 1POST:http:&#x2F;&#x2F;192.168.142.133:9200&#x2F;order&#x2F;_search 1.MUST同时匹配语法规则： 123456789101112131415161718&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match&quot;: &#123; &quot;orderName&quot;: &quot;遥控器&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;money&quot;: 8000 &#125; &#125; ] &#125; &#125;&#125; must关键字下面是个json数组，用来设置多个同时匹配的查询条件。用逗号隔开，我事先多创建了几条遥控器不同价格的数据，这里设置查询结果如下； 可见只查询出了一条数据 123456789101112131415161718192021222324252627282930&#123; &quot;took&quot;: 29, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 1, &quot;successful&quot;: 1, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: &#123; &quot;value&quot;: 1, &quot;relation&quot;: &quot;eq&quot; &#125;, &quot;max_score&quot;: 2.0776734, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;order&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;0fTBp3oB7hjRu-hq8c0j&quot;, &quot;_score&quot;: 2.0776734, &quot;_source&quot;: &#123; &quot;orderId&quot;: &quot;10003&quot;, &quot;money&quot;: 8000, &quot;orderName&quot;: &quot;遥控器&quot; &#125; &#125; ] &#125;&#125; 2.Should 表示条件或的关系请求示例： 1http:&#x2F;&#x2F;192.168.142.133:9200&#x2F;order&#x2F;_search 请求参数： 123456789101112131415161718&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;should&quot;: [ &#123; &quot;match&quot;: &#123; &quot;orderName&quot;: &quot;遥控器&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;orderName&quot;: &quot;电脑&quot; &#125; &#125; ] &#125; &#125;&#125; 部分结果如下 1234567891011121314151617181920212223242526272829303132333435363738&#123; &quot;took&quot;: 14, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 1, &quot;successful&quot;: 1, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: &#123; &quot;value&quot;: 6, &quot;relation&quot;: &quot;eq&quot; &#125;, &quot;max_score&quot;: 3.7518616, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;order&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;z_S-p3oB7hjRu-hq480k&quot;, &quot;_score&quot;: 3.7518616, &quot;_source&quot;: &#123; &quot;orderId&quot;: &quot;10001&quot;, &quot;money&quot;: 10000, &quot;orderName&quot;: &quot;电脑&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;order&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;0fTBp3oB7hjRu-hq8c0j&quot;, &quot;_score&quot;: 1.0776734, &quot;_source&quot;: &#123; &quot;orderId&quot;: &quot;10003&quot;, &quot;money&quot;: 8000, &quot;orderName&quot;: &quot;遥控器&quot; &#125; &#125;, 可以看到电脑和遥控器的数据都被查询出来了 3.range范围查询请求实例： 1PUT:http:&#x2F;&#x2F;192.168.142.133:9200&#x2F;order&#x2F;_search 语法规则 12345678910111213141516171819202122232425&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;should&quot;: [ &#123; &quot;match&quot;: &#123; &quot;orderName&quot;: &quot;遥控器&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;orderName&quot;: &quot;电脑&quot; &#125; &#125; ], &quot;filter&quot;:&#123; &quot;range&quot;:&#123; &quot;money&quot;:&#123; &quot;gt&quot;:9999 &#125; &#125; &#125; &#125; &#125;&#125; Range表示范围查询 gt是大于的意思 返回结果如下； 12345678910111213141516171819202122232425262728293031&#123; &quot;took&quot;: 11, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 1, &quot;successful&quot;: 1, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: &#123; &quot;value&quot;: 1, &quot;relation&quot;: &quot;eq&quot; &#125;, &quot;max_score&quot;: 3.7518616, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;order&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;z_S-p3oB7hjRu-hq480k&quot;, &quot;_score&quot;: 3.7518616, &quot;_source&quot;: &#123; &quot;orderId&quot;: &quot;10001&quot;, &quot;money&quot;: 10000, &quot;orderName&quot;: &quot;电脑&quot; &#125; &#125; ] &#125;&#125; 看到只查询出一条数据 4.精确 查询当使用文档保存数据的时候，ES会用数据进行一定的分词操作，并把分词后的数据放入到倒排索引中，所以查询数据的时候，就是全文检索 分词查询 例如： 1POST:http:&#x2F;&#x2F;192.168.142.133:9200&#x2F;order&#x2F;_search 请求参数： 1234567&#123; &quot;query&quot;: &#123; &quot;match&quot;:&#123; &quot;orderName&quot;:&quot;电&quot; &#125; &#125;&#125; 请求结果： 123456789101112131415161718192021222324252627282930&#123; &quot;took&quot;: 4, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 1, &quot;successful&quot;: 1, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: &#123; &quot;value&quot;: 1, &quot;relation&quot;: &quot;eq&quot; &#125;, &quot;max_score&quot;: 1.8759308, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;order&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;z_S-p3oB7hjRu-hq480k&quot;, &quot;_score&quot;: 1.8759308, &quot;_source&quot;: &#123; &quot;orderId&quot;: &quot;10001&quot;, &quot;money&quot;: 10000, &quot;orderName&quot;: &quot;电脑&quot; &#125; &#125; ] &#125;&#125; match_phrase匹配 上面也说了，保存的时候，会有一定的分词策略。所以对于短小词语,可能也能查询出来 新增一条数据 { ​ “orderId”:”10005”, ​ “money”:8004, ​ “orderName”:”遥控器制造有限公司” } 比方说，这个查询，分词结果可能是遥控器、制造、有限、公司、有限公司、制造有、一个字可能也是一个分词 例如： 1234567&#123; &quot;query&quot;: &#123; &quot;match_phrase&quot;: &#123; &quot;orderName&quot;: &quot;制有&quot; &#125; &#125;&#125; 这种不连着，就是查询出来 123456789101112131415161718&#123; &quot;took&quot;: 2, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 1, &quot;successful&quot;: 1, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: &#123; &quot;value&quot;: 0, &quot;relation&quot;: &quot;eq&quot; &#125;, &quot;max_score&quot;: null, &quot;hits&quot;: [] &#125;&#125; 10.聚合查询aggs:表示聚合操作 请求示例 1http:&#x2F;&#x2F;192.168.142.133:9200&#x2F;order&#x2F;_search 请求参数： 12345678910&#123; &quot;aggs&quot;: &#123; &quot;ls_money_group&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;money&quot; &#125; &#125; &#125;, &quot;size&quot;:0&#125; aggs:表示聚合查询 ls_money_group:分组后名称，随意写 terms：分组关键字 field : 分组字段 size:0 表示不要原始数据，只查询出分组数据 请求结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&#123; &quot;took&quot;: 35, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 1, &quot;successful&quot;: 1, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: &#123; &quot;value&quot;: 8, &quot;relation&quot;: &quot;eq&quot; &#125;, &quot;max_score&quot;: null, &quot;hits&quot;: [] &#125;, &quot;aggregations&quot;: &#123; &quot;ls_money_group&quot;: &#123; &quot;doc_count_error_upper_bound&quot;: 0, &quot;sum_other_doc_count&quot;: 0, &quot;buckets&quot;: [ &#123; &quot;key&quot;: 8004, &quot;doc_count&quot;: 2 &#125;, &#123; &quot;key&quot;: 8000, &quot;doc_count&quot;: 1 &#125;, &#123; &quot;key&quot;: 8001, &quot;doc_count&quot;: 1 &#125;, &#123; &quot;key&quot;: 8002, &quot;doc_count&quot;: 1 &#125;, &#123; &quot;key&quot;: 8003, &quot;doc_count&quot;: 1 &#125;, &#123; &quot;key&quot;: 9000, &quot;doc_count&quot;: 1 &#125;, &#123; &quot;key&quot;: 10000, &quot;doc_count&quot;: 1 &#125; ] &#125; &#125;&#125; key是字段值，可以看到按照金钱进行了排序操作 11.映射关系请求实例： 1PUT http:&#x2F;&#x2F;192.168.142.133:9200&#x2F;user&#x2F;_mapping 请求 参数 12345678910111213141516&#123; &quot;properties&quot;:&#123; &quot;name&quot;:&#123; &quot;type&quot;:&quot;text&quot;, // 表示可以分词 &quot;index&quot;:true // 支持索引 &#125;, &quot;class&quot;:&#123; &quot;type&quot;:&quot;keyword&quot;, // 表示不能分词，必须完成匹配 &quot;index&quot;:true &#125;, &quot;sex&quot;:&#123; &quot;type&quot;:&quot;keyword&quot;, &quot;index&quot;:false // 不支持索引 &#125; &#125;&#125; 使用GET 1http:&#x2F;&#x2F;192.168.142.133:9200&#x2F;user&#x2F;_mapping 获取刚才新增的操作 新增数据 1http:&#x2F;&#x2F;192.168.142.133:9200&#x2F;user&#x2F;create&#x2F;1001 12345&#123; &quot;name&quot;:&quot;泰罗奥特曼&quot;, &quot;class&quot;:&quot;M78星云&quot;, &quot;sex&quot;:&quot;男&quot;&#125; 检测效果 1234567&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;name&quot;:&quot;奥特们&quot; &#125; &#125;&#125; 结果： 123456789101112131415161718192021222324252627282930&#123; &quot;took&quot;: 459, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 1, &quot;successful&quot;: 1, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: &#123; &quot;value&quot;: 1, &quot;relation&quot;: &quot;eq&quot; &#125;, &quot;max_score&quot;: 0.5753642, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;user&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;1001&quot;, &quot;_score&quot;: 0.5753642, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;泰罗奥特曼&quot;, &quot;class&quot;: &quot;M78星云&quot;, &quot;sex&quot;: &quot;男&quot; &#125; &#125; ] &#125;&#125; 可以看到name字段支持分词映射查询 再看class班级字段 1234567&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;class&quot;:&quot;星云&quot; &#125; &#125;&#125; 查询结果； 123456789101112131415161718&#123; &quot;took&quot;: 4, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 1, &quot;successful&quot;: 1, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: &#123; &quot;value&quot;: 0, &quot;relation&quot;: &quot;eq&quot; &#125;, &quot;max_score&quot;: null, &quot;hits&quot;: [] &#125;&#125; 没有查询出数据keyword表示不支持分词查询 再看sex字段 1234567&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;sex&quot;:&quot;男&quot; &#125; &#125;&#125; 结果： 12345678910111213141516171819202122232425262728293031323334&#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;query_shard_exception&quot;, &quot;reason&quot;: &quot;failed to create query: Cannot search on field [sex] since it is not indexed.&quot;, &quot;index_uuid&quot;: &quot;jtcmDlaVQEupnH0HHdjVqw&quot;, &quot;index&quot;: &quot;user&quot; &#125; ], &quot;type&quot;: &quot;search_phase_execution_exception&quot;, &quot;reason&quot;: &quot;all shards failed&quot;, &quot;phase&quot;: &quot;query&quot;, &quot;grouped&quot;: true, &quot;failed_shards&quot;: [ &#123; &quot;shard&quot;: 0, &quot;index&quot;: &quot;user&quot;, &quot;node&quot;: &quot;PC6R73E1T9eHoK8ix4PhSg&quot;, &quot;reason&quot;: &#123; &quot;type&quot;: &quot;query_shard_exception&quot;, &quot;reason&quot;: &quot;failed to create query: Cannot search on field [sex] since it is not indexed.&quot;, &quot;index_uuid&quot;: &quot;jtcmDlaVQEupnH0HHdjVqw&quot;, &quot;index&quot;: &quot;user&quot;, &quot;caused_by&quot;: &#123; &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;Cannot search on field [sex] since it is not indexed.&quot; &#125; &#125; &#125; ] &#125;, &quot;status&quot;: 400&#125; 不支持索引查询","categories":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://lswisdom.github.io/categories/ElasticSearch/"}],"tags":[]},{"title":"ElasticSearch报错演示","slug":"elasticsearch/ElasticSearch报错演示","date":"2021-07-22T03:54:05.000Z","updated":"2021-07-25T09:09:37.848Z","comments":true,"path":"posts/809474901/","link":"","permalink":"https://lswisdom.github.io/posts/809474901/","excerpt":"","text":"错误提示一：[match_phrase] malformed query, expected [END_OBJECT] but found [FIELD_NAME]结果： 1234567891011121314151617&#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;parsing_exception&quot;, &quot;reason&quot;: &quot;[match_phrase] malformed query, expected [END_OBJECT] but found [FIELD_NAME]&quot;, &quot;line&quot;: 6, &quot;col&quot;: 9 &#125; ], &quot;type&quot;: &quot;parsing_exception&quot;, &quot;reason&quot;: &quot;[match_phrase] malformed query, expected [END_OBJECT] but found [FIELD_NAME]&quot;, &quot;line&quot;: 6, &quot;col&quot;: 9 &#125;, &quot;status&quot;: 400&#125; 错误提示二创建对象的时候 1http:&#x2F;&#x2F;192.168.142.133:9200&#x2F;user&#x2F;_create&#x2F;1001 改为 1http:&#x2F;&#x2F;192.168.142.133:9200&#x2F;user&#x2F;_doc&#x2F;1001 12345678910111213&#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;mapper [sex] cannot be changed from type [keyword] to [text]&quot; &#125; ], &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;mapper [sex] cannot be changed from type [keyword] to [text]&quot; &#125;, &quot;status&quot;: 400&#125; 维基百科地址： 1https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;65031413&#x2F;elasticsearch-7-9-0-cannot-be-changed-from-type-keyword-to-text","categories":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://lswisdom.github.io/categories/ElasticSearch/"}],"tags":[]},{"title":"centos7下安装ElasticSearch","slug":"linux/centos7下安装ElasticSearch","date":"2021-04-18T11:25:45.000Z","updated":"2021-08-15T13:26:12.621Z","comments":true,"path":"posts/3121942040/","link":"","permalink":"https://lswisdom.github.io/posts/3121942040/","excerpt":"","text":"CentOS7安装ElasticSearch7.121.安装JDK安装JDK 并配置环境变量,配置如下： 1234export JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;software&#x2F;jdk1.8.0_281export JRE_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;software&#x2F;jdk1.8.0_281&#x2F;jreexport CLASSPATH&#x3D;.:$JAVA_HOME&#x2F;lib&#x2F;dt.jar:$JAVA_HOME&#x2F;lib&#x2F;tools.jar:$JRE_HOME&#x2F;libexport PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin 2.安装ElasticSearch注意：我下载的是7版本,需要jdk11的支持，但是开发环境我选择 jdk1.8 ​下载6版本的可以使用jdk1.8 ElasticSearch文档地址：https://www.elastic.co/guide/en/elasticsearch/reference/current/elasticsearch-intro.htmlElasticSearch下载地址：https://www.elastic.co/cn/downloads/elasticsearch 1tar -zxvf elasticsearch-7.12.0-linux-x86_64.tar.gz 下载完成后的地址路径如下： 3.启动ES,并解决ES启动报错进入bin目录下面执行 ./elasticsearch 错误一：ES7.12 需要使用JDK11的版本报错，提示信息如下： 1234distribution with a bundled JDK, ensure the JAVA_HOME environment variable is not set.warning: usage of JAVA_HOME is deprecated, use ES_JAVA_HOMEFuture versions of Elasticsearch will require Java 11; your Java version from [/usr/local/software/jdk1.8.0_281/jre] does not meet this requirement. Consider switching to a distribution of Elasticsearch with a bundled JDK. If you are already using a distribution with a bundled JDK, ensure the JAVA_HOME environment variable is not set.[2021-04-18T19:54:57,709][ERROR][o.e.b.ElasticsearchUncaughtExceptionHandler] [MiWiFi-R3-srv] uncaught exception in thread [main] 这个意思提示我们，使用ES7.12需要jdk11的版本下载安装jdk11,并修改es需要的jdk环境变量修改vim elasticsearch 文件,并在文件最上方添加如下配置： 12345678910#配置自己的jdk11export JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;jdk-11.0.10&#x2F;export PATH&#x3D;$JAVA_HOME&#x2F;bin:$PATH#添加jdk判断if [ -x &quot;$JAVA_HOME&#x2F;bin&#x2F;java&quot; ]; then JAVA&#x3D;&quot;&#x2F;usr&#x2F;local&#x2F;jdk-11.0.10&#x2F;bin&#x2F;java&quot;else JAVA&#x3D;&#96;which java&#96;fi 再次启动ES ./elasticsearch 错误二：Es提示我们不可以使用root用户 提示信息如下： 123456789101112java.lang.RuntimeException: can not run elasticsearch as root at org.elasticsearch.bootstrap.Bootstrap.initializeNatives(Bootstrap.java:101) at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:168) at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:397) at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:159) at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:150) at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:75) at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:116) at org.elasticsearch.cli.Command.main(Command.java:79) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:115) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:81)For complete error details, refer to the log at &#x2F;usr&#x2F;local&#x2F;software&#x2F;elasticsearch-7.12.0&#x2F;logs&#x2F;elasticsearch.log 解决办法：创建新用户，并用新用户进行启动创建用户组：groupadd esgroup创建es用户：useradd esuser -g esgroup -p 123456然后使用chown命令来让这个文件夹属于这个用户chown -R esuser:esgroup elasticsearch-7.12.0切换用户，使用新用户esuser进行服务启动 再次启动,启动成功后，使用curl 127.0.0.1:9200 进行访问，如果返回一段json。说明启动成功了 12345678910111213141516171819[root@MiWiFi-R3-srv bin]# curl 127.0.0.1:9200&#123; &quot;name&quot; : &quot;MiWiFi-R3-srv&quot;, &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;cluster_uuid&quot; : &quot;htoKhKvMRfCpzscUQLWWAQ&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;7.12.0&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;tar&quot;, &quot;build_hash&quot; : &quot;78722783c38caa25a70982b5b042074cde5d3b3a&quot;, &quot;build_date&quot; : &quot;2021-03-18T06:17:15.410153305Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;8.8.0&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 但是ES默认支持localhost启动，修改配置文件config下面的vim elasticsearch.yml 如下图所示启动完成后，重新启动，又出现了新的警告信息 错误三：Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release这个是警告信息，垃圾回收器的问题，可以不修改 1Java HotSpot(TM) 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release. 错误四：提示：在启动Elasticsearch之前，您必须解决以下行中描述的要点提示信息如下： 123456ERROR: [3] bootstrap checks failed. You must address the points described in the following [3] lines before starting Elasticsearch.bootstrap check failure [1] of [3]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535]bootstrap check failure [2] of [3]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]bootstrap check failure [3] of [3]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configuredERROR: Elasticsearch did not exit normally - check the logs at &#x2F;usr&#x2F;local&#x2F;software&#x2F;elasticsearch-7.12.0&#x2F;logs&#x2F;elasticsearch.log 4.第一个错误，意思大概是：elasticsearch进程的文件描述符[4096]过低，增加到至少[65535]解决方案： 修改 vim /etc/security/limits.conf 在文件最下方加入如下配置：注意：第一列是你刚才创建的用户名称,我刚才创建的用户是esuser esuser soft nofile 65536esuser hard nofile 65536esuser soft nproc 4096esuser hard nproc 4096 5.第二个错误，意思大概是：虚拟机最大的虚拟内存区域。max_map_count[65530]太低，增加到至少[262144]解决办法：进入/etc 修改sysctl.conf文档，里面都是注释，添加如下面一行配置 1vm.max_map_count&#x3D;655360 推荐信息提示至少262144 保存信息wq注意：配置如果想要生效，需要执行如下配置： 6.第三个错误：解决办法：在elasticsearch的config目录下，修改elasticsearch.yml配置文件，将下面的配置加入到该配置文件中：注意：这里的node-1为node-name配置的值 1cluster.initial_master_nodes: [&quot;node-1&quot;] 注意默认情况下：node-name的值是注释掉的。这里要放开 7. 重新启动ES 看看效果,启动完成后,还是提示这个错误 check failure [1] of [1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535]这种情况,可能是配置没有生效,重启虚拟机再看看效果重新启动完成后，再次启动提示start，表示已经正常启动了 8.windows电脑无法直接访问开放9200端口 12firewall-cmd --zone&#x3D;public --add-port&#x3D;9200&#x2F;tcp --permanentfirewall-cmd --reload 使用windows客户端访问，能看到正常返回json了","categories":[{"name":"linux","slug":"linux","permalink":"https://lswisdom.github.io/categories/linux/"}],"tags":[{"name":"Linux环境安装","slug":"Linux环境安装","permalink":"https://lswisdom.github.io/tags/Linux%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"}]},{"title":"使用CAS实现单点登录一","slug":"linux/CAS实现单点登录","date":"2021-04-14T23:32:10.000Z","updated":"2021-07-25T09:09:47.242Z","comments":true,"path":"posts/3633779439/","link":"","permalink":"https://lswisdom.github.io/posts/3633779439/","excerpt":"","text":"一、CAS服务器的搭建地址：github地址：https://github.com/apereo/cas-overlay-template 1.1 服务部署和测试clone下来依赖包,下载后的依赖包,需要手动创建src/main/resources 目录,并在该目录下面创建application.properties文件和log4j2.xml文件log4j2.xml文件,主要是为了设置CAS的日志输出目录application.properties目录：一些数据库配置、证书配置等配置完成后,打包部署在tomcat的webapp目录下面 等待CAS服务启动之后,通过http://localhost:8080/cas/login可以使用默认的账号：casuser Mellon登录 二、配置application.propertis 文件,通过数据库验证2.1 pom.xml中添加依赖文件123456789101112&lt;dependency&gt; &lt;groupId&gt;org.postgresql&lt;&#x2F;groupId&gt; &lt;artifactId&gt;postgresql&lt;&#x2F;artifactId&gt; &lt;version&gt;42.2.18.jre7&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt;&lt;!-- https:&#x2F;&#x2F;mvnrepository.com&#x2F;artifact&#x2F;org.apereo.cas&#x2F;cas-server-support-jdbc --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;&#x2F;groupId&gt; &lt;artifactId&gt;cas-server-support-jdbc&lt;&#x2F;artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; 注释掉默认的用户配置： 1#cas.authn.accept.users&#x3D;casuser::Mellon 2.2 添加jdbc认证2.2.1 这是使用数据库连接的配置123456789cas.authn.jdbc.query[0].driverClass&#x3D;org.postgresql.Drivercas.authn.jdbc.query[0].url&#x3D;jdbc:postgresql:&#x2F;&#x2F;127.0.0.1:5432&#x2F;postgrescas.authn.jdbc.query[0].user&#x3D;postgrescas.authn.jdbc.query[0].password&#x3D;passwordcas.authn.jdbc.query[0].sql&#x3D;select * from sys_user where username&#x3D;?# 字段的列明cas.authn.jdbc.query[0].fieldPassword&#x3D;passwordcas.authn.jdbc.query[0].passwordEncoder.characterEncoding&#x3D;UTF-8 2.2.2 MD5加密配置如果密码进行加盐配置,需要增加如下配置,这样数据库中存储的事MD5加密的密码,CAS页面输入的密码还是原始的密码就可以登录 123cas.authn.jdbc.query[0].passwordEncoder.encodingAlgorithm&#x3D;MD5cas.authn.jdbc.query[0].passwordEncoder.type&#x3D;DEFAULTcas.authn.jdbc.query[0].passwordEncoder.characterEncoding&#x3D;UTF-8 2.2.3 密码加盐加密简单的MD5值太简单,需要加盐值的配置 12345678910111213141516# 加盐配置#配置数据库连接cas.authn.jdbc.encode[0].driverClass&#x3D;org.postgresql.Drivercas.authn.jdbc.encode[0].url&#x3D;jdbc:postgresql:&#x2F;&#x2F;127.0.0.1:5432&#x2F;postgrescas.authn.jdbc.encode[0].user&#x3D;postgrescas.authn.jdbc.encode[0].password&#x3D;password#加密迭代次数cas.authn.jdbc.encode[0].numberOfIterations&#x3D;1024# 数据库存放的动态盐值的字段列明cas.authn.jdbc.encode[0].saltFieldName&#x3D;PasswordSaltcas.authn.jdbc.encode[0].sql&#x3D;select * from sys_user where username&#x3D;?cas.authn.jdbc.encode[0].algorithmName&#x3D;MD5# 哪个字段作为密码字段cas.authn.jdbc.encode[0].passwordFieldName&#x3D;password application.properties文件的模板如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149### CAS Server Context Configuration#server.context-path&#x3D;&#x2F;casserver.port&#x3D;8443# CAS 的访问需要https证书,在这里配置server.ssl.key-store&#x3D;E:&#x2F;download&#x2F;tomcat.keystoreserver.ssl.key-store-password&#x3D;123456server.ssl.key-password&#x3D;123456server.max-http-header-size&#x3D;2097152server.use-forward-headers&#x3D;trueserver.connection-timeout&#x3D;20000server.error.include-stacktrace&#x3D;ALWAYSserver.compression.enabled&#x3D;trueserver.compression.mime-types&#x3D;application&#x2F;javascript,application&#x2F;json,application&#x2F;xml,text&#x2F;html,text&#x2F;xml,text&#x2F;plainserver.tomcat.max-http-post-size&#x3D;2097152server.tomcat.basedir&#x3D;build&#x2F;tomcatserver.tomcat.accesslog.enabled&#x3D;trueserver.tomcat.accesslog.pattern&#x3D;%t %a &quot;%r&quot; %s (%D ms)server.tomcat.accesslog.suffix&#x3D;.logserver.tomcat.min-spare-threads&#x3D;10server.tomcat.max-threads&#x3D;200server.tomcat.port-header&#x3D;X-Forwarded-Portserver.tomcat.protocol-header&#x3D;X-Forwarded-Protoserver.tomcat.protocol-header-https-value&#x3D;httpsserver.tomcat.remote-ip-header&#x3D;X-FORWARDED-FORserver.tomcat.uri-encoding&#x3D;UTF-8spring.http.encoding.charset&#x3D;UTF-8spring.http.encoding.enabled&#x3D;truespring.http.encoding.force&#x3D;true### CAS Cloud Bus Configuration#spring.cloud.bus.enabled&#x3D;false# Indicates that systemPropertiesOverride can be used.# Set to false to prevent users from changing the default accidentally. Default true.spring.cloud.config.allow-override&#x3D;true# External properties should override system properties.spring.cloud.config.override-system-properties&#x3D;false# When allowOverride is true, external properties should take lowest priority, and not override any# existing property sources (including local config files).spring.cloud.config.override-none&#x3D;false# spring.cloud.bus.refresh.enabled&#x3D;true# spring.cloud.bus.env.enabled&#x3D;true# spring.cloud.bus.destination&#x3D;CasCloudBus# spring.cloud.bus.ack.enabled&#x3D;trueendpoints.enabled&#x3D;falseendpoints.sensitive&#x3D;trueendpoints.restart.enabled&#x3D;falseendpoints.shutdown.enabled&#x3D;false# Control the security of the management&#x2F;actuator endpoints# The &#39;enabled&#39; flag below here controls the rendering of details for the health endpoint amongst other things.management.security.enabled&#x3D;truemanagement.security.roles&#x3D;ACTUATOR,ADMINmanagement.security.sessions&#x3D;if_requiredmanagement.context-path&#x3D;&#x2F;statusmanagement.add-application-context-header&#x3D;false# Define a CAS-specific &quot;WARN&quot; status code and its ordermanagement.health.status.order&#x3D;WARN, DOWN, OUT_OF_SERVICE, UNKNOWN, UP# Control the security of the management&#x2F;actuator endpoints# With basic authentication, assuming Spring Security and&#x2F;or relevant modules are on the classpath.security.basic.authorize-mode&#x3D;rolesecurity.basic.path&#x3D;&#x2F;cas&#x2F;status&#x2F;**# security.basic.enabled&#x3D;true# security.user.name&#x3D;casuser# security.user.password&#x3D;### CAS Web Application Session Configuration#server.session.timeout&#x3D;300server.session.cookie.http-only&#x3D;trueserver.session.tracking-modes&#x3D;COOKIE### CAS Thymeleaf View Configuration#spring.thymeleaf.encoding&#x3D;UTF-8spring.thymeleaf.cache&#x3D;truespring.thymeleaf.mode&#x3D;HTMLspring.thymeleaf.template-resolver-order&#x3D;100### CAS Log4j Configuration## logging.config&#x3D;file:&#x2F;etc&#x2F;cas&#x2F;log4j2.xmlserver.context-parameters.isLog4jAutoInitializationDisabled&#x3D;true### CAS AspectJ Configuration#spring.aop.auto&#x3D;truespring.aop.proxy-target-class&#x3D;true## 添加认证服务cas.tgc.secure&#x3D;falsecas.serviceRegistry.initFromJson&#x3D;true### CAS Authentication Credentials## 默认的登录正好和密码#cas.authn.accept.users&#x3D;casuser::Mellon# 加盐配置#配置数据库连接#cas.authn.jdbc.encode[0].driverClass&#x3D;org.postgresql.Driver#cas.authn.jdbc.encode[0].url&#x3D;jdbc:postgresql:&#x2F;&#x2F;127.0.0.1:5432&#x2F;postgres#cas.authn.jdbc.encode[0].user&#x3D;postgres#cas.authn.jdbc.encode[0].password&#x3D;password#加密迭代次数#cas.authn.jdbc.encode[0].numberOfIterations&#x3D;1024# 数据库存放的动态盐值的字段列明#cas.authn.jdbc.encode[0].saltFieldName&#x3D;PasswordSalt#cas.authn.jdbc.encode[0].sql&#x3D;select * from sys_user where username&#x3D;?#cas.authn.jdbc.encode[0].algorithmName&#x3D;MD5# 哪个字段作为密码字段#cas.authn.jdbc.encode[0].passwordFieldName&#x3D;passwordcas.authn.jdbc.query[0].driverClass&#x3D;org.postgresql.Drivercas.authn.jdbc.query[0].url&#x3D;jdbc:postgresql:&#x2F;&#x2F;127.0.0.1:5432&#x2F;postgrescas.authn.jdbc.query[0].user&#x3D;postgrescas.authn.jdbc.query[0].password&#x3D;password#cas.authn.jdbc.query[0].numberOfIterations&#x3D;1024#cas.authn.jdbc.query[0].saltFieldName&#x3D;PasswordSaltcas.authn.jdbc.query[0].sql&#x3D;select * from sys_user where username&#x3D;?cas.authn.jdbc.query[0].passwordEncoder.encodingAlgorithm&#x3D;MD5cas.authn.jdbc.query[0].fieldPassword&#x3D;passwordcas.authn.jdbc.query[0].passwordEncoder.type&#x3D;DEFAULTcas.authn.jdbc.query[0].passwordEncoder.characterEncoding&#x3D;UTF-8 log4j2.xml文件的模板如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot; ?&gt;&lt;!-- Specify the refresh internal in seconds. --&gt;&lt;Configuration monitorInterval&#x3D;&quot;5&quot; packages&#x3D;&quot;org.apereo.cas.logging&quot;&gt; &lt;Properties&gt; &lt;Property name&#x3D;&quot;baseDir&quot;&gt;D:\\device-logs&lt;&#x2F;Property&gt; &lt;&#x2F;Properties&gt; &lt;Appenders&gt; &lt;Console name&#x3D;&quot;console&quot; target&#x3D;&quot;SYSTEM_OUT&quot;&gt; &lt;PatternLayout pattern&#x3D;&quot;%d %p [%c] - &lt;%m&gt;%n&quot;&#x2F;&gt; &lt;&#x2F;Console&gt; &lt;RollingFile name&#x3D;&quot;file&quot; fileName&#x3D;&quot;$&#123;baseDir&#125;&#x2F;cas.log&quot; append&#x3D;&quot;true&quot; filePattern&#x3D;&quot;$&#123;baseDir&#125;&#x2F;cas-%d&#123;yyyy-MM-dd-HH&#125;-%i.log&quot;&gt; &lt;PatternLayout pattern&#x3D;&quot;%highlight&#123;%d %p [%c] - &lt;%m&gt;&#125;%n&quot;&#x2F;&gt; &lt;Policies&gt; &lt;OnStartupTriggeringPolicy &#x2F;&gt; &lt;SizeBasedTriggeringPolicy size&#x3D;&quot;10 MB&quot;&#x2F;&gt; &lt;TimeBasedTriggeringPolicy &#x2F;&gt; &lt;&#x2F;Policies&gt; &lt;DefaultRolloverStrategy max&#x3D;&quot;5&quot; compressionLevel&#x3D;&quot;9&quot;&gt; &lt;Delete basePath&#x3D;&quot;$&#123;baseDir&#125;&quot; maxDepth&#x3D;&quot;2&quot;&gt; &lt;IfFileName glob&#x3D;&quot;*&#x2F;*.log.gz&quot; &#x2F;&gt; &lt;IfLastModified age&#x3D;&quot;7d&quot; &#x2F;&gt; &lt;&#x2F;Delete&gt; &lt;&#x2F;DefaultRolloverStrategy&gt; &lt;&#x2F;RollingFile&gt; &lt;RollingFile name&#x3D;&quot;auditlogfile&quot; fileName&#x3D;&quot;$&#123;baseDir&#125;&#x2F;cas_audit.log&quot; append&#x3D;&quot;true&quot; filePattern&#x3D;&quot;$&#123;baseDir&#125;&#x2F;cas_audit-%d&#123;yyyy-MM-dd-HH&#125;-%i.log&quot;&gt; &lt;PatternLayout pattern&#x3D;&quot;%d %p [%c] - %m%n&quot;&#x2F;&gt; &lt;Policies&gt; &lt;OnStartupTriggeringPolicy &#x2F;&gt; &lt;SizeBasedTriggeringPolicy size&#x3D;&quot;10 MB&quot;&#x2F;&gt; &lt;TimeBasedTriggeringPolicy &#x2F;&gt; &lt;&#x2F;Policies&gt; &lt;DefaultRolloverStrategy max&#x3D;&quot;5&quot; compressionLevel&#x3D;&quot;9&quot;&gt; &lt;Delete basePath&#x3D;&quot;$&#123;baseDir&#125;&quot; maxDepth&#x3D;&quot;2&quot;&gt; &lt;IfFileName glob&#x3D;&quot;*&#x2F;*.log.gz&quot; &#x2F;&gt; &lt;IfLastModified age&#x3D;&quot;7d&quot; &#x2F;&gt; &lt;&#x2F;Delete&gt; &lt;&#x2F;DefaultRolloverStrategy&gt; &lt;&#x2F;RollingFile&gt; &lt;RollingFile name&#x3D;&quot;perfFileAppender&quot; fileName&#x3D;&quot;$&#123;baseDir&#125;&#x2F;perfStats.log&quot; append&#x3D;&quot;true&quot; filePattern&#x3D;&quot;$&#123;baseDir&#125;&#x2F;perfStats-%d&#123;yyyy-MM-dd-HH&#125;-%i.log&quot;&gt; &lt;PatternLayout pattern&#x3D;&quot;%m%n&quot;&#x2F;&gt; &lt;Policies&gt; &lt;OnStartupTriggeringPolicy &#x2F;&gt; &lt;SizeBasedTriggeringPolicy size&#x3D;&quot;10 MB&quot;&#x2F;&gt; &lt;TimeBasedTriggeringPolicy &#x2F;&gt; &lt;&#x2F;Policies&gt; &lt;DefaultRolloverStrategy max&#x3D;&quot;5&quot; compressionLevel&#x3D;&quot;9&quot;&gt; &lt;Delete basePath&#x3D;&quot;$&#123;baseDir&#125;&quot; maxDepth&#x3D;&quot;2&quot;&gt; &lt;IfFileName glob&#x3D;&quot;*&#x2F;*.log.gz&quot; &#x2F;&gt; &lt;IfLastModified age&#x3D;&quot;7d&quot; &#x2F;&gt; &lt;&#x2F;Delete&gt; &lt;&#x2F;DefaultRolloverStrategy&gt; &lt;&#x2F;RollingFile&gt; &lt;CasAppender name&#x3D;&quot;casAudit&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;auditlogfile&quot; &#x2F;&gt; &lt;&#x2F;CasAppender&gt; &lt;CasAppender name&#x3D;&quot;casFile&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;file&quot; &#x2F;&gt; &lt;&#x2F;CasAppender&gt; &lt;CasAppender name&#x3D;&quot;casConsole&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;console&quot; &#x2F;&gt; &lt;&#x2F;CasAppender&gt; &lt;CasAppender name&#x3D;&quot;casPerf&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;perfFileAppender&quot; &#x2F;&gt; &lt;&#x2F;CasAppender&gt; &lt;&#x2F;Appenders&gt; &lt;Loggers&gt; &lt;AsyncLogger name&#x3D;&quot;com.couchbase&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot; includeLocation&#x3D;&quot;true&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.apereo.cas.web.CasWebApplication&quot; level&#x3D;&quot;info&quot; additivity&#x3D;&quot;false&quot; includeLocation&#x3D;&quot;true&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.springframework.security&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.springframework.boot.autoconfigure.security&quot; level&#x3D;&quot;info&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.jasig.cas.client&quot; level&#x3D;&quot;info&quot; additivity&#x3D;&quot;false&quot; includeLocation&#x3D;&quot;true&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.apereo&quot; level&#x3D;&quot;info&quot; additivity&#x3D;&quot;false&quot; includeLocation&#x3D;&quot;true&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.apereo.services.persondir&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot; includeLocation&#x3D;&quot;true&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.apache&quot; level&#x3D;&quot;error&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.springframework.cloud&quot; level&#x3D;&quot;info&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.springframework.cloud.context&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.springframework.boot&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.springframework&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.springframework.aop&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.springframework.boot.actuate.autoconfigure&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.springframework.webflow&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.springframework.session&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.springframework.amqp&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.springframework.integration&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.springframework.messaging&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.springframework.web&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.springframework.orm.jpa&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.springframework.scheduling&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.thymeleaf&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.pac4j&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.opensaml&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;net.sf.ehcache&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;com.ryantenney.metrics&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;console&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;file&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;net.jradius&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.openid4java&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.ldaptive&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;com.hazelcast&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.springframework.context.annotation&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot; &#x2F;&gt; &lt;AsyncLogger name&#x3D;&quot;org.springframework.boot.devtools&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot; &#x2F;&gt; &lt;AsyncLogger name&#x3D;&quot;org.jasig.spring&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.springframework.web.socket&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.apache.cxf&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.apache.http&quot; level&#x3D;&quot;off&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;perfStatsLogger&quot; level&#x3D;&quot;info&quot; additivity&#x3D;&quot;false&quot; includeLocation&#x3D;&quot;true&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casPerf&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.apereo.cas.web.flow&quot; level&#x3D;&quot;info&quot; additivity&#x3D;&quot;true&quot; includeLocation&#x3D;&quot;true&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncLogger name&#x3D;&quot;org.apereo.inspektr.audit.support&quot; level&#x3D;&quot;info&quot; includeLocation&#x3D;&quot;true&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casAudit&quot;&#x2F;&gt; &lt;AppenderRef ref&#x3D;&quot;casFile&quot;&#x2F;&gt; &lt;&#x2F;AsyncLogger&gt; &lt;AsyncRoot level&#x3D;&quot;error&quot;&gt; &lt;AppenderRef ref&#x3D;&quot;casConsole&quot;&#x2F;&gt; &lt;&#x2F;AsyncRoot&gt; &lt;&#x2F;Loggers&gt;&lt;&#x2F;Configuration&gt;","categories":[{"name":"linux","slug":"linux","permalink":"https://lswisdom.github.io/categories/linux/"}],"tags":[]},{"title":"CentOS7安装MYSLQ5.7","slug":"linux/CentOS7安装MySQL5.7","date":"2021-04-05T09:54:08.000Z","updated":"2021-07-25T09:09:47.326Z","comments":true,"path":"posts/1192933728/","link":"","permalink":"https://lswisdom.github.io/posts/1192933728/","excerpt":"","text":"CentOS7.3安装mysql第一步：下载和安装mysql源 1.先下载 mysql源安装包 1wget https:&#x2F;&#x2F;dev.mysql.com&#x2F;get&#x2F;mysql57-community-release-el7-11.noarch.rpm 2.安装mysql源 1yum -y localinstall mysql57-community-release-el7-11.noarch.rpm 第二步：在线安装Mysql 1yum -y install mysql-community-server 下载的东西比较多,要稍微等会 第三步：启动Mysql服务 1systemctl start mysqld 第四步：设置开机启动 123systemctl enable mysqldsystemctl daemon-reload 第五步：修改root本地登录密码 mysql安装完成之后，在/var/log/mysqld.log文件中给root生成了一个临时的默认密码。 [root@localhost ~]# vi /var/log/mysqld.log 这里的临时密码 eMV.R#mWe3ha [root@localhost ~]# mysql -u root -p Enter password: 输入临时密码 进入mysql命令行； 1234mysql&gt; ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;ZhipengWang2012@&#39;;Query OK, 0 rows affected (0.00 sec) 修改密码为 ZhipengWang2012@ (备注 mysql5.7默认密码策略要求密码必须是大小写字母数字特殊字母的组合，至少8位) 第七步：设置允许远程登录 Mysql默认不允许远程登录，我们需要设置下，并且防火墙开放3306端口； 123456mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;@LiShuai123&#39; WITH GRANT OPTION;Query OK, 0 rows affected, 1 warning (0.01 sec)mysql&gt; exit;Bye 退出下； centos7开启防火墙 123456789101112[root@localhost ~]# firewall-cmd --zone&#x3D;public --add-port&#x3D;3306&#x2F;tcp --permanentsuccess[root@localhost ~]# firewall-cmd --reloadsuccess[root@localhost ~]# 开放3306端口 第八步：配置默认编码为utf8 修改/etc/my.cnf配置文件，在[mysqld]下添加编码配置，如下所示： [mysqld] character_set_server=utf8 init_connect=’SET NAMES utf8’ [root@localhost ~]# vi /etc/my.cnf 编辑保存完 重启mysql服务； [root@localhost ~]# systemctl restart mysqld [root@localhost ~]# 查看下编码： 12345678910111213141516171819202122232425262728mysql&gt; show variables like &#39;%character%&#39;;+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | &#x2F;usr&#x2F;share&#x2F;mysql&#x2F;charsets&#x2F; |+--------------------------+----------------------------+8 rows in set (0.00 sec) 注:都安装成功了之后，那个tar.gz的压缩包就可以删掉了，节省磁盘空间 linux下的mysql默认是大小写敏感的，通过java操作数据库的时候会出现找不到表的情况，需要设置大小写不敏感 12vim &#x2F;etc&#x2F;my.cnf[mysqld]后添加添加lower_case_table_names&#x3D;1 12345虚拟机中mysql的地址如下：10.9.32.171账号root密码：root CentOs6.8安装mysql https://www.cnblogs.com/saneri/p/6617415.html","categories":[{"name":"linux","slug":"linux","permalink":"https://lswisdom.github.io/categories/linux/"}],"tags":[{"name":"环境安装","slug":"环境安装","permalink":"https://lswisdom.github.io/tags/%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"}]},{"title":"Hello World","slug":"hello-world","date":"2021-04-04T04:49:43.900Z","updated":"2021-07-25T04:57:15.595Z","comments":true,"path":"posts/1243066710/","link":"","permalink":"https://lswisdom.github.io/posts/1243066710/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://lswisdom.github.io/categories/SpringBoot/"},{"name":"Redis","slug":"Redis","permalink":"https://lswisdom.github.io/categories/Redis/"},{"name":"linux","slug":"linux","permalink":"https://lswisdom.github.io/categories/linux/"},{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://lswisdom.github.io/categories/ElasticSearch/"}],"tags":[{"name":"SpringBoot -","slug":"SpringBoot","permalink":"https://lswisdom.github.io/tags/SpringBoot/"},{"name":"Redis","slug":"Redis","permalink":"https://lswisdom.github.io/tags/Redis/"},{"name":"Linux环境安装","slug":"Linux环境安装","permalink":"https://lswisdom.github.io/tags/Linux%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"},{"name":"环境安装","slug":"环境安装","permalink":"https://lswisdom.github.io/tags/%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"}]}